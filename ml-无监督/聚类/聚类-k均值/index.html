<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  
  <link rel="shortcut icon" href="../../../img/favicon.ico">
  <title>聚类k均值 - daily-goal</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700" />

  <link rel="stylesheet" href="../../../css/theme.css" />
  <link rel="stylesheet" href="../../../css/theme_extra.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" />
  
  <script>
    // Current page data
    var mkdocs_page_name = "\u805a\u7c7bk\u5747\u503c";
    var mkdocs_page_input_path = "ml-\u65e0\u76d1\u7763/\u805a\u7c7b/\u805a\u7c7b-k\u5747\u503c.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
        <a href="../../.." class="icon icon-home"> daily-goal</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../..">Projects</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Documents</span></p>
                <ul class="current">
                    <li class="toctree-l1"><a class="reference internal" href="#">第一部分</a>
    <ul>
                <li class="toctree-l2"><a class="" href="../../../chapters/chapter1/post01.md">数据结构</a>
                </li>
                <li class="toctree-l2"><a class="" href="../../../chapters/chapter1/post02.md">IO操作</a>
                </li>
    </ul>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="#">第二部分</a>
    <ul>
                <li class="toctree-l2"><a class="" href="../../../chapters/chapter2/post03.md">多线程</a>
                </li>
                <li class="toctree-l2"><a class="" href="../../../chapters/chapter2/post04.md">面向对象编程</a>
                </li>
                <li class="toctree-l2"><a class="" href="../../../chapters/chapter2/post05.md">网络编程</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="#">备忘录</a>
    <ul>
                <li class="toctree-l3"><a class="" href="../../../chapters/chapter2/temp/temp01.md">我爱你</a>
                </li>
                <li class="toctree-l3"><a class="" href="../../../chapters/chapter2/temp/temp02.md">买个锤子</a>
                </li>
    </ul>
                </li>
    </ul>
                    </li>
                    <li class="toctree-l1 current"><a class="reference internal current" href="#">ml无监督</a>
    <ul class="current">
                <li class="toctree-l2"><a class="reference internal" href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/">机器学习无监督学习</a>
                </li>
                <li class="toctree-l2 current"><a class="reference internal current" href="#">ml无监督聚类</a>
    <ul class="current">
                <li class="toctree-l3"><a class="reference internal" href="../%E8%81%9A%E7%B1%BB-%E5%88%86%E5%B1%82%E5%B1%82%E6%AC%A1/">聚类分层层次</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../%E8%81%9A%E7%B1%BB-Isodata/">聚类Isodata</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../%E8%81%9A%E7%B1%BB-kmeans%2B%2B/">聚类kmeans++</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../%E8%81%9A%E7%B1%BB-DBSCAN/">聚类DBSCAN</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../%E8%81%9A%E7%B1%BB-SOM-kmeans/">聚类SOMkmeans</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../%E8%81%9A%E7%B1%BB-EM%E7%AE%97%E6%B3%95/">聚类EM算法</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../%E8%81%9A%E7%B1%BB-%E6%94%BE%E5%B0%84%E4%BC%A0%E6%92%AD/">聚类放射传播</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../%E8%81%9A%E7%B1%BB/">聚类</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../%E8%81%9A%E7%B1%BB-GMM-Kmeans/">聚类GMMKmeans</a>
                </li>
                <li class="toctree-l3 current"><a class="reference internal current" href="./">聚类k均值</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../%E8%81%9A%E7%B1%BB-SOM/">聚类SOM</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE/%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE-%E7%89%B9%E5%BE%81%E9%80%89%E5%8F%96-%E7%9B%B8%E5%85%B3%E6%80%A7%E9%98%88%E5%80%BC/">维度灾难特征选取相关性阈值</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE/%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE-%E7%89%B9%E5%BE%81%E9%80%89%E5%8F%96-%E9%80%90%E6%AD%A5%E6%90%9C%E7%B4%A2/">维度灾难特征选取逐步搜索</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="#">ml无监督维度灾难</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE/%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE-%E7%89%B9%E5%BE%81%E9%80%89%E5%8F%96-%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/">维度灾难特征选取遗传算法</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE/%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE-%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/">维度灾难特征提取</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE/%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE/">维度灾难</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE/%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE-%E7%89%B9%E5%BE%81%E9%80%89%E5%8F%96/">维度灾难特征选取</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE/%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE-%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96-%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/">维度灾难特征提取主成分分析</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE/%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE-%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96-LDAPCA/">维度灾难特征提取LDAPCA</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE/%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE-%E7%89%B9%E5%BE%81%E9%80%89%E5%8F%96-%E6%96%B9%E5%B7%AE%E9%98%88%E5%80%BC/">维度灾难特征选取方差阈值</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE/%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE-%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96-%E8%87%AA%E7%BC%96%E7%A0%81%E6%9C%BA/">维度灾难特征提取自编码机</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE/%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE-%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96-%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90/">维度灾难特征提取线性判别分析</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../%E5%8C%97%E4%BA%AC/%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE/">维度灾难</a>
                </li>
    </ul>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">关于我们</span></p>
                <ul>
                    <li class="toctree-l1"><a class="" href="../../../about.md">About</a>
                    </li>
                </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../../..">daily-goal</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../..">Docs</a> &raquo;</li>
    
      
        
          <li>ml无监督聚类 &raquo;</li>
        
      
        
          <li>ml无监督 &raquo;</li>
        
      
        
          <li>Documents &raquo;</li>
        
      
    
    <li>聚类k均值</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <p><strong>K 均值</strong></p>
<p>K 均值是基于样本点间的几何距离来度量聚类的通用目的算法。由于集群围绕在聚类中心，结果会接近于球状并具有相似的大小。</p>
<p>我们之所以推荐该算法给初学者，是因为它不仅足够简单，而且足够灵活，对于大多数问题都能给出合理的结果。</p>
<p>是一个简单的聚类算法，把n的对象根据他们的属性分为k个分割，k&lt; n。算法的核心就是要优化失真函数J,使其收敛到局部最小值但不是全局最小值。</p>
<p>“它的基本思想是，通过迭代方式寻找K个簇（Cluster）的一种划分方案，使得聚类结果对应的代价函数最小。特别地，代价函数可以定义为各个样本距离所属簇中心点的误差平方和”</p>
<p><img alt="image-20200519093940986" src="../images/image-20200519093940986.png" /></p>
<p>关于K-Means聚类的文章，参见机器学习算法-K-means聚类。关于K-Means的推导，里面可是有大学问的，蕴含着强大的EM思想。 </p>
<p><img alt="image-20200519094759320" src="../images/image-20200519094759320.png" /></p>
<p><img alt="image-20200519094808969" src="../images/image-20200519094808969.png" /></p>
<p><img alt="image-20200519094934089" src="../images/image-20200519094934089.png" /></p>
<ul>
<li><strong>优点</strong>：</li>
<li>K 均值是最为流行的聚类算法，因为它足够快速、足够简单，如果你的预处理数据和特征工程都做得十分有效，那它将具备令人惊叹的灵活性。</li>
<li>算法简单，容易实现 ；</li>
<li>算法速度很快；</li>
<li>对处理大数据集，该算法是相对可伸缩的和高效率的，因为它的复杂度大约是O(nkt)，其中n是所有对象的数目，k是簇的数目,t是迭代的次数。通常k&lt;&lt;n。这个算法通常局部收敛。“但一般情况下达到的局部最优已经可以满足聚类的需求。”</li>
<li>算法尝试找出使平方误差函数值最小的k个划分。当簇是密集的、球状或团状的，且簇与簇之间区别明显时，聚类效果较好。</li>
<li><strong>缺点</strong>：</li>
<li>该算法需要指定集群的数量，而 K 值的选择通常都不是那么容易确定的。另外，如果训练数据中的真实集群并不是类球状的，那么 K 均值聚类会得出一些比较差的集群。</li>
<li>对数据类型要求较高，适合数值型数据；</li>
<li>可能收敛到局部最小值，在大规模数据上收敛较慢</li>
<li>分组的数目k是一个输入参数，不合适的k可能返回较差的结果。</li>
<li>对初值的簇心值敏感，对于不同的初始值，可能会导致不同的聚类结果；</li>
<li>不适合于发现非凸面形状的簇，或者大小差别很大的簇。</li>
<li>对于”噪声”和孤立点数据敏感，少量的该类数据能够对平均值产生极大影响。</li>
<li>“受初值和离群点的影响每次的结果不稳定、</li>
<li>结果通常不是全局最优而是局部最优解、</li>
<li>无法很好地解决数据簇分布差别比较大的情况（比如一类是另一类样本数量的100倍）、</li>
<li>不太适用于离散分类等”</li>
<li>
<p>“样本点只能被划分到单一的类中。”</p>
</li>
<li>
<p><strong>实现</strong>：</p>
</li>
</ul>
<blockquote>
<p>Python - http://scikit-learn.org/stable/modules/clustering.html#k-means</p>
<p>R - https://stat.ethz.ch/R-manual/R-devel/library/stats/html/kmeans.html</p>
</blockquote>
<p>调优</p>
<p>“（1）数据归一化和离群点处理。</p>
<p>K均值聚类本质上是一种基于欧式距离度量的数据划分方法，均值和方差大的维度将对数据的聚类结果产生决定性的影响，所以未做归一化处理和统一单位的数据是无法直接参与运算和比较的。同时，离群点或者少量的噪声数据就会对均值产生较大的影响，导致中心偏移，因此使用K均值聚类算法之前通常需要对数据做预处理。</p>
<p>（2）合理选择K值。</p>
<p>K值的选择是K均值聚类最大的问题之一，这也是K均值聚类算法的主要缺点。实际上，我们希望能够找到一些可行的办法来弥补这一缺点，或者说找到K值的合理估计方法。但是，K值的选择一般基于经验和多次实验结果。例如采用手肘法，我们可以尝试不同的K值，并将不同K值所对应的损失函数画成折线，横轴为K“的取值，纵轴为误差平方和所定义的损失函数，如图5.3所示。</p>
<p><img alt="image-20200519113859938" src="../images/image-20200519113859938.png" /></p>
<p><img alt="image-20200519113915356" src="../images/image-20200519113915356.png" /></p>
<p>“（3）采用核函数。”</p>
<p>采用核函数是另一种可以尝试的改进方向。传统的欧式距离度量方式，使得K均值算法本质上假设了各个数据簇的数据具有一样的先验概率，并呈现球形或者高”“维球形分布，这种分布在实际生活中并不常见。面对非凸的数据分布形状时，可能需要引入核函数来优化，这时算法又称为核K均值算法，是核聚类方法的一种[6]。核聚类方法的主要思想是通过一个非线性映射，将输入空间中的数据点映射到高位的特征空间中，并在新的特征空间中进行聚类。非线性映射增加了数据点线性可分的概率，从而在经典的聚类算法失效的情况下，通过引入核函数可以达到更为准确的聚类结果。”</p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../%E8%81%9A%E7%B1%BB-SOM/" class="btn btn-neutral float-right" title="聚类SOM">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../%E8%81%9A%E7%B1%BB-GMM-Kmeans/" class="btn btn-neutral" title="聚类GMMKmeans"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
      <p>Copyright © 2020</p>
    
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../%E8%81%9A%E7%B1%BB-GMM-Kmeans/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../%E8%81%9A%E7%B1%BB-SOM/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '../../..';</script>
    <script src="../../../js/theme.js" defer></script>
      <script src="../../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
